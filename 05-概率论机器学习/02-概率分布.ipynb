{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d53839",
   "metadata": {},
   "source": [
    "这一节开始，介绍一些常用的概率分布（其实主要为了后续的LDA（隐狄利克雷分配）模型做准备），首先让我们从一枚硬币开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a3a27",
   "metadata": {},
   "source": [
    "## 伯努利分布\n",
    "假设我们手头有一枚硬币，用随机变量$x$描述扔硬币的结果，记$x=1$表示正面，$x=0$表示反面，另外$x=1$发生的概率记为$\\mu$，那么$x=0$的概率就为$1-\\mu$（$\\mu$未必为0.5），那么伯努利分布就是抛一次硬币的概率分布：    \n",
    "\n",
    "$$\n",
    "Bern(x\\mid \\mu)=\\mu^x(1-\\mu)^{1-x}\n",
    "$$   \n",
    "\n",
    "### 均值、方差\n",
    "\n",
    "接着，我们可以很容易的求出该分布的均值、方差：    \n",
    "\n",
    "$$\n",
    "E[x]=1*u+0*(1-u)=u\\\\\n",
    "var[x]=E[(x-E[x])^2]=E[x^2]-(E[x])^2=1^2*u+0^2*(1-u)-u^2=u-u^2\n",
    "$$   \n",
    "\n",
    "### 极大似然估计\n",
    "\n",
    "接下来，我们需要考虑考虑一个问题，假如给了我们一堆iid采样的样本$X=\\{x_1,x_2,...,x_N\\}$，如何去估计伯努利分布的参数$\\mu$，常用的一种方式就是极大似然估计，首先写出它的似然函数：    \n",
    "\n",
    "$$\n",
    "p(X\\mid\\mu)=\\prod_{i=1}^N[\\mu^{x_i}(1-\\mu)^{1-x_i}]\n",
    "$$   \n",
    "\n",
    "那么，其对数似然函数为：   \n",
    "\n",
    "$$\n",
    "ln[p(X\\mid\\mu)]=\\sum_{i=1}^N[x_iln\\mu+(1-x_i)ln(1-\\mu)]\n",
    "$$   \n",
    "\n",
    "令$ln[p(X\\mid\\mu)]$关于$\\mu$的导数为0，可求得：   \n",
    "\n",
    "$$\n",
    "\\mu_{ML}=\\frac{m}{N}\n",
    "$$   \n",
    "\n",
    "其中，$m=\\sum_{i=1}^Nx_i$。因此在极大似然估计的框架下，正面向上发生的概率是数据集里正面向上的观测所占的比例，但同时我们也可以发现一个问题，那就是如果观测量很少，极大似然估计的结果会出现**过拟合**的情况，比如我们连续抛一枚硬币3次，碰巧3次都是正面朝上，那么$N=m=3$，则$\\mu_{ML}=1$，这显然不太合理，后面我们会引入关于$\\mu$的先验概率来得到一个更加合理的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7fc14",
   "metadata": {},
   "source": [
    "## 二项分布\n",
    "接下来我们对问题做一个的升级，假设我们一共抛了硬币$N$次，其中关于正面$x=1$出现次数$m$的概率分布称为二项分布，根据前面的推导，我们可以很容易写出它的分布：    \n",
    "\n",
    "$$\n",
    "Bin(m\\mid N,\\mu)=\\binom{N}{m}\\mu^m(1-\\mu)^{N-m}\n",
    "$$  \n",
    "\n",
    "其中，$\\binom{N}{m}=\\frac{N!}{(N-m)!m!}$，即$N$种组合中出现$m$次正面朝上的概率   \n",
    "\n",
    "### 均值、方差\n",
    "如何按照定义求解会稍稍有些麻烦，由于二项分布可以看做$N$次独立的伯努利事件，那么**加和的均值等于均值的加和，加和的方差等于方差的加和**，我们知道$m=x_1+x_2+\\cdots+x_N$，所以：   \n",
    "\n",
    "$$\n",
    "E[m]=E[x_1]+E[x_2]+\\cdots+E[x_N]=N\\mu\\\\\n",
    "var[m]=var[x_1]+var[x_2]+\\cdots+var[x_N]=N\\mu(1-\\mu)\n",
    "$$\n",
    "\n",
    "### 极大似然估计\n",
    "二项分布的极大似然估计求解其实和伯努利分布的求解一样，即在$N$次独立的伯努利实验中正面朝上出现的次数$m$所占的比例：    \n",
    "\n",
    "$$\n",
    "\\mu_{ML}=\\frac{m}{N}\n",
    "$$   \n",
    "\n",
    "那么，接下来让我们解决一下上面提到的过拟合问题，即为$\\mu$引入一个先验分布$p(\\mu)$，而对于二项分布比较有用的一个先验分布便是Beta分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b407cef",
   "metadata": {},
   "source": [
    "## Beta分布\n",
    "\n",
    "在构建先验分布时，我们往往想偷懒，因为如果先验分布比较复杂，再让它与似然函数相乘，那么后验的求解会更加困难，所以我们希望找到一种先验分布，它与似然函数相乘后也是易于分析的，最直接的一种方式就是构造一种与似然函数结构类似的先验分布，比如二项分布为某个因子与$\\mu^m(1-\\mu)^{N-m}$相乘的结果，那么我们同样构造一个类似结构先验分布，那么它们的乘积也会具有相同的结构，**即找到一个先验分布，让它与似然函数相乘后具有和先验分布相同的函数形式，这样的性质被称为共轭性**，那么我们可以假设我们的先验项中包含有$\\mu^a(1-\\mu)^b$这么一项，直观理解就是，我们先验分布中抛了$a+b$次硬币，其中$a$次正面朝上，$b$次反面朝上，由于需要做成一个分布，所以我们还需要找到一个归一化系数$\\beta$，使得：   \n",
    "\n",
    "$$\n",
    "\\int_0^1\\beta\\mu^a(1-\\mu)^bd\\mu=1\n",
    "$$   \n",
    "\n",
    "这里直接写出这个系数的表达式：   \n",
    "\n",
    "$$\n",
    "\\beta=\\frac{\\Gamma(a+b+2)}{\\Gamma(a+1)\\Gamma(b+1)}\n",
    "$$\n",
    "\n",
    "其中，$\\Gamma(\\cdot)$为Gamma函数，它的定义如下：   \n",
    "\n",
    "$$\n",
    "\\Gamma(x)=\\int_0^{\\infty}t^{x-1}e^{-t}dt\n",
    "$$  \n",
    "\n",
    "它看起来很奇怪，但它有一个很有用的性质：   \n",
    "\n",
    "$$\n",
    "\\Gamma(x)=(x-1)\\Gamma(x-1)\n",
    "$$  \n",
    "\n",
    "\n",
    "更多关于Gamma函数的由来，推荐博客：[《神奇的Gamma函数》](http://www.52nlp.cn/lda-math-%E7%A5%9E%E5%A5%87%E7%9A%84gamma%E5%87%BD%E6%95%B01)，接下来，我们就可以得到这个分布的形式了：   \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid a,b)=\\frac{\\Gamma(a+b+2)}{\\Gamma(a+1)\\Gamma(b+1)}\\mu^a(1-\\mu)^b\n",
    "$$  \n",
    "\n",
    "但是呢...这个分布不是很美观，对超参做一个简单调整，令$a=a-1,b=b-1$，就得到了我们最终Beta分布的形式了：       \n",
    "\n",
    "$$\n",
    "Beta(\\mu\\mid a,b)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\mu^{a-1}(1-\\mu)^{b-1}\n",
    "$$  \n",
    "\n",
    "这里，$a,b$是先验分布中的超参数，关于不同$a,b$取值下的$\\mu$的分布如下图\n",
    "\n",
    "<img src=\"../images/beta分布的超参数.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "\n",
    "可以发现一些简单的规律，比如若$a=1,b=1$，Beta分布则为$(0,1)$上的均匀分布，再比如随着$a,b$取值的增加，分布的“峰”会更尖，说明方差会越小，分布会越集中\n",
    "### 均值、方差\n",
    "对于期望的求解，我们需要用到分布中自带的一个有用的性质：    \n",
    "\n",
    "$$\n",
    "\\int_0^1\\mu^{a-1}(1-\\mu)^{b-1}d\\mu=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n",
    "$$   \n",
    "\n",
    "所以，均值：   \n",
    "\n",
    "$$\n",
    "E[\\mu]=\\int_0^1\\mu\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\mu^{a-1}(1-\\mu)^{b-1}d\\mu\\\\\n",
    "=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\int_0^1\\mu^{(a+1)-1}(1-\\mu)^{b-1}d\\mu\\\\\n",
    "=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\frac{\\Gamma(a+1)\\Gamma(b)}{\\Gamma(a+b+1)}\\\\\n",
    "=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\frac{a\\Gamma(a)\\Gamma(b)}{(a+b)\\Gamma(a+b)}\\\\\n",
    "=\\frac{a}{a+b}\n",
    "$$   \n",
    "\n",
    "$E[\\mu^2]$的推导与$E[\\mu]$类似，只是上面积分项中$\\mu^{(a+1)-1}$变化为$\\mu^{(a+2)-1}$，所以： \n",
    "\n",
    "$$\n",
    "E[\\mu^2]=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\frac{\\Gamma(a+2)\\Gamma(b)}{\\Gamma(a+b+2)}\\\\\n",
    "=\\frac{a(a+1)}{(a+b)(a+b+1)}\n",
    "$$   \n",
    "\n",
    "所以，方差：   \n",
    "\n",
    "$$\n",
    "var[\\mu]=E[\\mu^2]-(E[\\mu])^2=\\frac{ab}{(a+b)^2(a+b+1)}\n",
    "$$   \n",
    "\n",
    "### 后验分布\n",
    "接下来看看后验概率分布长什么样子，我们将Beta分布和上面的二项分布相乘后，可以整理得到：    \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid m,l,a,b)=\\frac{\\Gamma(m+a+l+b)}{\\Gamma(m+a)\\Gamma(l+b)}\\mu^{m+a-1}(1-\\mu)^{l+b-1}\n",
    "$$   \n",
    "\n",
    "这里，$N=m+l$，可以发现这也是一个Beta分布，即$Beta(\\mu\\mid a+m,b+l)$，显然这样的结果看起来也很make sense，我们可以通过它的均值来直观感受一下：   \n",
    "\n",
    "$$\n",
    "E[u]=\\frac{m+a}{m+a+l+b}\n",
    "$$\n",
    "\n",
    "### 贝叶斯推断\n",
    "\n",
    "既然写出了后验分布的形式，那接下来就可以做预测了，比如下一次抛出正面的概率为：      \n",
    "\n",
    "$$\n",
    "\\int_0^1Bern(x=1\\mid\\mu)p(\\mu\\mid m,l,a,b)d\\mu=\\int_0^1\\mu p(\\mu\\mid m,l,a,b)d\\mu=E_{p(\\mu\\mid m,l,a,b)}[u]=\\frac{m+a}{m+a+l+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90538f0",
   "metadata": {},
   "source": [
    "### 证明补充\n",
    "\n",
    "接下来对上面的内容做一些证明补充，第一个问题是若随机变量独立，那么它们的和的均值等于它们均值的和，以及它们的和的方差等于它们方差的和，第二个问题是Beta分布中归一化系数的推导，下面先看看第一个问题     \n",
    "\n",
    "（1）问题一，为了方便，这就可以推导两个独立的随机变量的情况，多个独立随机变量的推导类似，我们假设随机变量$x,y$独立，那么需要证明：    \n",
    "\n",
    "$$\n",
    "E[x+y]=E[x]+E[y]\\\\\n",
    "var[x+y]=var[x]+var[y]\n",
    "$$  \n",
    "\n",
    "下面证明一下，由于$x,y$独立，所以有$p(x,y)=p(x)p(y)$    \n",
    "\n",
    "所以，均值：    \n",
    "\n",
    "$$\n",
    "E[x+y]=\\int p(x,y)(x+y)dxdy\\\\\n",
    "=\\int p(x)p(y)(x+y)dxdy\\\\\n",
    "=\\int p(x)p(y)xdxdy+\\int p(x)p(y)ydxdy\\\\\n",
    "=[\\int p(x)xdx][\\int p(y)dy]+[\\int p(y)ydy][\\int p(x)dx]\\\\\n",
    "=\\int p(x)xdx+\\int p(y)ydy\\\\\n",
    "=E[x]+E[y]\n",
    "$$   \n",
    "\n",
    "方差：   \n",
    "\n",
    "$$\n",
    "var[x+y]=\\int\\int((x+y)-E[x+y])^2p(x,y)dxdy\\\\\n",
    "=\\int\\int((x-E[x])+(y-E[y]))^2p(x)p(y)dxdy（根据上面的推导，可以把E[x+y]拆开为E[x]+E[y]）\\\\\n",
    "=\\int\\int((x-E[x])^2+(y-E[y])^2+2(x-E[x])(y-E[y]))p(x)p(y)dxdy\\\\\n",
    "=[\\int(x-E[x])^2p(x)dx][\\int p(y)dy]+[\\int(y-E[y])^2p(y)dy][\\int p(x)dx]+2[\\int(x-E[x])p(x)dx][\\int(y-E[y])p(y)dy]\\\\\n",
    "=\\int(x-E[x])^2p(x)dx+\\int(y-E[y])^2p(y)dy+2(E[x]-E[x])(E[y]-E[y])\\\\\n",
    "=var[x]+var[y]\n",
    "$$   \n",
    "\n",
    "（2）问题二，Beta分布中归一化系数的推导其实就是验证下面的等式成立：    \n",
    "\n",
    "$$\n",
    "\\int_0^1\\mu^{a-1}(1-\\mu)^{b-1}d\\mu=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n",
    "$$   \n",
    "\n",
    "以下推导[参考自>>>](https://blog.csdn.net/lanchunhui/article/details/75647076)，我们假设$t=x+y$，那么：   \n",
    "\n",
    "$$\n",
    "\\Gamma(a)\\Gamma(b)=\\int_0^\\infty e^{-x}x^{a-1}dx\\int_0^\\infty e^{-y}y^{b-1}dy\\\\\n",
    "=\\int_0^\\infty e^{-x}x^{a-1}[\\int_x^\\infty e^{x-t}(t-x)^{b-1}dt]dx（令y=t-x）\\\\\n",
    "=\\int_0^\\infty x^{a-1}[\\int_x^\\infty e^{-t}(t-x)^{b-1}dt]dx\\\\\n",
    "=\\int_0^\\infty e^{-t}[\\int_0^t x^{a-1}(t-x)^{b-1}dx]dt（交换积分顺序）\\\\\n",
    "=\\int_0^\\infty e^{-t}[\\int_0^1 (t\\mu)^{a-1}(t-t\\mu)^{b-1}td\\mu]dt（令x=t\\mu）\\\\\n",
    "=\\int_0^\\infty e^{-t}t^{a+b-1}dt\\int_0^1 \\mu^{a-1}(1-\\mu)^{b-1}d\\mu\\\\\n",
    "=\\Gamma(a+b)\\int_0^1 \\mu^{a-1}(1-\\mu)^{b-1}d\\mu\n",
    "$$  \n",
    "\n",
    "所以：   \n",
    "\n",
    "$$\n",
    "\\int_0^1\\mu^{a-1}(1-\\mu)^{b-1}d\\mu=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2faa7a",
   "metadata": {},
   "source": [
    "## 多项分布及狄利克雷分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c7533",
   "metadata": {},
   "source": [
    "这一节，我们不抛硬币了，来抛一抛骰子，首先让我们从抛一次骰子开始，假设该骰子共有$K$面（没说非要是6面...），显然每次的结果只能是这$K$种可能中的一种，我们可以将抛出的结果表示成一个$K$维的one-hot向量（仅有一个维度为1，其余维度全部为0的向量）：   \n",
    "\n",
    "$$\n",
    "x=(0,...,0,1,0,...)^T\n",
    "$$  \n",
    "\n",
    "用参数$\\mu_k$表示$x_k=1,k=1,2,...,K$的概率，所以全部的参数可以表示为：   \n",
    "\n",
    "$$\n",
    "\\mu=(\\mu_1,\\mu_2,...,\\mu_K)^T\n",
    "$$  \n",
    "\n",
    "由于要满足概率分布，所以有$\\mu_k\\geq 0,\\sum_{k=1}^T\\mu_k=1$，那么抛一次骰子的概率分布可以表示为：   \n",
    "\n",
    "$$\n",
    "p(x\\mid \\mu)=\\prod_{k=1}^K\\mu_k^{x_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300ba98",
   "metadata": {},
   "source": [
    "### 多项分布\n",
    "\n",
    "那么如果我们有$N$个骰子（参数相同），全部抛一次（相互独立），记出现第$k$面（$k=1,2,...,K$）的次数为$m_k$，显然$m_k\\geq 0,\\sum_{k=1}^K=N$，那么关于$m_k$的的概率分布可以表示为：   \n",
    "\n",
    "$$\n",
    "Mult(m_1,m_2,...,m_K\\mid\\mu,N)=\\binom{N}{m_1m_2\\cdots m_K}\\prod_{k=1}^K\\mu_k^{m_k}\n",
    "$$   \n",
    "\n",
    "这便是多项式分布，其中归一化系数为：   \n",
    "\n",
    "$$\n",
    "\\binom{N}{m_1m_2\\cdots m_K}=\\frac{N!}{m_1!m_2!\\cdots m_K!}\n",
    "$$  \n",
    "\n",
    "直观上，归一化系数也很好理解，可以看做将$N$个骰子分成抛面数分别为$m_1,m_2,...,m_K$的$K$组的方案总数\n",
    "\n",
    "#### 极大似然估计\n",
    "极大似然估计与前一节的求解类似，这里就直接写结果了：   \n",
    "\n",
    "$$\n",
    "\\mu_k^{ML}=\\frac{m_k}{N}\n",
    "$$  \n",
    "\n",
    "类似地，为了避免极大似然估计带来的过拟合问题，我们可以为$\\mu$引入一个先验分布，通常选择狄利克雷分布作为多项式分布的先验分布..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11068eba",
   "metadata": {},
   "source": [
    "### 二.狄利克雷分布\n",
    "\n",
    "为什么是狄利克雷分布勒？因为它与多项式分布共轭，它包含有类似于$\\prod_{k=1}^K\\mu_k^{m_k}$的项，定义如下：   \n",
    "\n",
    "$$\n",
    "Dir(\\mu\\mid\\alpha)=\\frac{\\Gamma(\\alpha_0)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_K)}\\prod_{k=1}^K\\mu_k^{\\alpha_k-1}\n",
    "$$  \n",
    "\n",
    "其中，$\\alpha=(\\alpha_1,...,\\alpha_K)^T,\\alpha_0=\\sum_{k=1}^K\\alpha_k$，如下图，是三个变量的狄利克雷分布，左图是$\\alpha=(0.1,0.1,0.1)^T$的情况，中图是$\\alpha=(1,1,1)^T$的情况，右图是$\\alpha=(10,10,10)^T$的情况：   \n",
    "\n",
    "<img src=\"../images/狄利克雷分布.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "底部是$\\mu_1,\\mu_2,\\mu_3$所张成的三角区域，由于需要满足$0\\leq\\mu_k \\leq 1,\\sum_{k=1}^3\\mu_k=1$的条件，所以它们的取值范围只能被限制在一个三角区域内，该区域也是一个单纯形，如下图所示：   \n",
    "\n",
    "<img src=\"../images/单纯形.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "#### 后验分布\n",
    "显然，后验分布满足下面的关系：   \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid\\alpha,m)\\propto p(m\\mid\\mu)p(\\mu\\mid\\alpha)\\propto\\prod_{k=1}^K\\mu_k^{\\alpha_k+m_k-1}\n",
    "$$  \n",
    "\n",
    "所以，它也是一个狄利克雷分布，形式如下：    \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid\\alpha,m)=Dir(\\mu\\mid\\alpha+m)=\\frac{\\Gamma(N+\\alpha_0)}{\\Gamma(\\alpha_1+m_1)\\cdots\\Gamma(\\alpha_K+m_K)}\\prod_{k=1}^K\\mu_k^{\\alpha_k+m_k-1}\n",
    "$$   \n",
    "\n",
    "其中，$m=(m_1,...,m_K),\\alpha=(\\alpha_1,...,\\alpha_K),N=\\sum_{k=1}^Km_k,\\alpha_0=\\sum_{k=1}^K\\alpha_k$\n",
    "\n",
    "#### 贝叶斯推断\n",
    "\n",
    "有了后验分布，我们就可以做贝叶斯推断了\n",
    "\n",
    "$$\n",
    "p(x_k=1\\mid m,\\alpha)\\\\\n",
    "=\\int p(x_k=1\\mid\\mu)p(\\mu\\mid\\alpha,m)d\\mu\\\\\n",
    "=\\int\\mu_k\\frac{\\Gamma(N+\\alpha_0)}{\\Gamma(\\alpha_1+m_1)\\cdots\\Gamma(\\alpha_K+m_K)}\\prod_{i=1}^K\\mu_i^{\\alpha_i+m_i-1}d\\mu\\\\\n",
    "=\\frac{\\Gamma(N+\\alpha_0)}{\\Gamma(\\alpha_1+m_1)\\cdots\\Gamma(\\alpha_K+m_K)}\\int\\mu_k\\prod_{i=1}^K\\mu_i^{\\alpha_i+m_i-1}d\\mu\\\\\n",
    "=\\frac{\\Gamma(N+\\alpha_0)}{\\Gamma(\\alpha_1+m_1)\\cdots\\Gamma(\\alpha_K+m_K)}\\frac{\\Gamma(\\alpha_1+m_1)\\cdots\\Gamma(\\alpha_k+m_k+1)\\cdots\\Gamma(\\alpha_K+m_K)}{\\Gamma(N+\\alpha_0+1)}\\\\\n",
    "=\\frac{\\Gamma(N+\\alpha_0)}{\\Gamma(\\alpha_k+m_k)}\\frac{\\Gamma(\\alpha_k+m_k+1)}{\\Gamma(N+\\alpha_0+1)}\\\\\n",
    "=\\frac{\\alpha_k+m_k}{N+\\alpha_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76b697",
   "metadata": {},
   "source": [
    "## 高斯分布（正态分布）及其共轭先验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96eaa8",
   "metadata": {},
   "source": [
    "前两讲分别抛了硬币和骰子，这一节抛啥？还是抛硬币，而且要可劲儿的抛，那抛完硬币看啥？看硬币正面出现的概率，即$\\frac{m}{N}$，这里$N$表示抛硬币的次数，$m=X_1+X_2+\\cdots+X_N$，表示正面出现的次数，$X_i=1$表示正面，$X_i=0$表示反面，下面演示一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08044041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05b8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先定义抛一次硬币的过程\n",
    "def toss_a_coin():\n",
    "    return np.random.rand()<0.5 #假设正面的概率为0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bb9a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hezhiqiang01/Desktop/anaconda/anaconda3/envs/ACG/lib/python3.6/site-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#定义次数\n",
    "N=[10,500,1000,5000]\n",
    "plt.figure(figsize = (18,4))\n",
    "for index,num in enumerate(N):\n",
    "    p=[]\n",
    "    for _ in range(0,200):\n",
    "        c=0\n",
    "        for _ in range(0,num):\n",
    "            c+=toss_a_coin() \n",
    "        p.append(c/num)\n",
    "    plt.subplot(1,4,index+1)\n",
    "    plt.hist(p,normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0856d81",
   "metadata": {},
   "source": [
    "可以发现统计量$\\frac{m}{N}$有服从正态分布的趋势，均值稳定在0.5，而方差越来越小（峰越来越尖）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115fd5c4",
   "metadata": {},
   "source": [
    "### 正态分布的定义\n",
    "对于一元变量的情况，正态分布可以写作：   \n",
    "\n",
    "$$\n",
    "N(x\\mid\\mu,\\sigma^2)=\\frac{1}{(2\\pi\\sigma^2)^{\\frac{1}{2}}}exp\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\}\n",
    "$$  \n",
    "\n",
    "其中，$\\mu$是均值，$\\sigma^2$是方差，对于$D$维向量$x$，它的高斯分布写作：   \n",
    "\n",
    "$$\n",
    "N(x\\mid\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{\\frac{D}{2}}}\\frac{1}{|\\Sigma|^{\\frac{1}{2}}}exp\\{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\}\n",
    "$$  \n",
    "\n",
    "其中，$\\mu$是一个$D$维的均值向量，$\\Sigma$是一个$D\\times D$的协方差矩阵，$|\\Sigma|$是$\\Sigma$的行列式\n",
    "\n",
    "#### 均值、协方差\n",
    "下面直接写一下均值和协方差...\n",
    "$$\n",
    "E[x]=\\mu\\\\\n",
    "var[x]=E[(x-E[x])(x-E[x])^T]=\\Sigma\n",
    "$$   \n",
    "\n",
    "#### 极大似然估计\n",
    "$$\n",
    "\\mu_{ML}=\\frac{1}{N}\\sum_{i=1}^Nx_i\\\\\n",
    "\\Sigma_{ML}=\\frac{1}{N}\\sum_{i=1}^N(x_i-\\mu_{ML})(x_i-\\mu_{ML})^T\n",
    "$$   \n",
    "\n",
    "这里需要注意下协方差的极大似然估计是有偏的，即   \n",
    "\n",
    "$$\n",
    "E[\\Sigma_{ML}]=\\frac{N-1}{N}\\Sigma\n",
    "$$   \n",
    "\n",
    "#### 条件概率分布以及边缘概率分布\n",
    "\n",
    "对于多元高斯分布，它的条件概率分布以及边缘概率分布也是一个高斯分布，我们不妨将随机变量拆为两部分：     \n",
    "\n",
    "$$\n",
    "x=\\binom{x_a}{x_b}\n",
    "$$   \n",
    "\n",
    "那么，对应的均值和协方差可以写作：    \n",
    "\n",
    "$$\n",
    "\\mu=\\binom{\\mu_a}{\\mu_b}\\\\\n",
    "\\Sigma=\\begin{pmatrix}\n",
    "\\Sigma_{aa} & \\Sigma_{ab}\\\\ \n",
    "\\Sigma_{ba} & \\Sigma_{bb}\n",
    "\\end{pmatrix}\n",
    "$$   \n",
    "\n",
    "有时为了方便表示，我们会直接用到协方差矩阵的逆，称为精度，可以写作：    \n",
    "\n",
    "$$\n",
    "\\Lambda = \\Sigma^{-1}=\\begin{pmatrix}\n",
    "\\Lambda_{aa} & \\Lambda_{ab}\\\\ \n",
    "\\Lambda_{ba} & \\Lambda_{bb}\n",
    "\\end{pmatrix}\n",
    "$$   \n",
    "\n",
    "那么**条件概率分布**公式：  \n",
    "\n",
    "$$\n",
    "p(x_a\\mid x_b)=N(x_a\\mid \\mu_{a\\mid b},\\Lambda_{aa}^{-1})\n",
    "$$   \n",
    "\n",
    "这里，$\\mu_{a\\mid b}=\\mu_a-\\Lambda_{aa}^{-1}\\Lambda_{ab}(x_b-\\mu_b)$，接下来，**边缘概率分布**的公式：   \n",
    "\n",
    "$$\n",
    "p(x_a)=N(x_a\\mid\\mu_a,\\Sigma_{aa})\n",
    "$$   \n",
    "\n",
    "如下图，左侧是两个变量上的高斯联合概率分布$p(x_a,x_b)$的轮廓线（绿色），右侧是边缘概率分布$p(x_a)$（蓝色）和$x_b=0.7$的条件概率分布$p(x_a\\mid x_b)$（红色曲线）\n",
    "\n",
    "<img src=\"../images/高斯条件概率与边缘概率.png\" width=\"40%\">\n",
    "\n",
    "接下来，让我们继续看看正态分布的共轭先验..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177f34b",
   "metadata": {},
   "source": [
    "### 二.共轭先验\n",
    "\n",
    "这一节就只推导一维高斯分布的共轭先验，我们首先假设$\\sigma^2$是已知的情况下，推导$\\mu$的共轭先验，然后再假设$\\mu$已知的情况下，推导$\\sigma^2$的共轭先验，然后再假设$\\mu,\\sigma^2$均未知的情况下，推导其共轭先验\n",
    "\n",
    "#### $\\sigma^2$已知的情况\n",
    "假设$\\sigma^2$已知，我们有一组观测$X=\\{x_1,x_2,...,x_N\\}$，假设均值为$\\mu$，那么此时的似然函数可以看做是关于$\\mu$的函数：   \n",
    "\n",
    "$$\n",
    "p(X\\mid\\mu)=\\prod_{i=1}^Np(x_n\\mid\\mu)=\\frac{1}{(2\\pi\\sigma^2)^{\\frac{N}{2}}}exp\\{-\\frac{1}{2\\sigma^2}\\sum_{n=1}^N(x_n-\\mu)^2\\}\n",
    "$$   \n",
    "\n",
    "接下来需要找到一个$p(u)$，让它与$p(X\\mid\\mu)$相乘后具有与$p(u)$相同的形式，显然$p(\\mu)$同样选择一个高斯分布就可以满足，因为都只有指数部分含有$\\mu$，而且是关于$\\mu$的二次函数，这样就可以将他们整合在一起了，我们不妨假设先验概率分布如下：   \n",
    "\n",
    "$$\n",
    "p(\\mu)=N(\\mu\\mid\\mu_0,\\sigma_0^2)\n",
    "$$   \n",
    "\n",
    "从而后验概率：   \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid X)\\propto p(X\\mid\\mu)p(\\mu)\n",
    "$$   \n",
    "\n",
    "对指数部分进行配方整理后，可以得到后验概率分布的形式为：    \n",
    "\n",
    "$$\n",
    "p(\\mu\\mid X)=N(\\mu\\mid\\mu_N,\\sigma_N^2)\n",
    "$$  \n",
    "\n",
    "其中：   \n",
    "\n",
    "$$\n",
    "\\mu_N=\\frac{\\sigma^2}{N\\sigma_0^2+\\sigma^2}\\mu_0+\\frac{N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\\mu_{ML}\\\\\n",
    "\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}\n",
    "$$  \n",
    "\n",
    "这里$\\mu_{ML}$是$\\mu$的最大似然解，即：   \n",
    "\n",
    "$$\n",
    "\\mu_{ML}=\\frac{1}{N}\\sum_{n=1}^Nx_n\n",
    "$$  \n",
    "\n",
    "通过上面的公式，我们可以得到一些有意思的结论：   \n",
    "\n",
    "（1）当$N=0$时，后概率分布等于先验概率分布，这在我们意料之中；    \n",
    "（2）当$N\\rightarrow\\infty$时，后验均值等于最大似然的均值，后验方差趋近于0，说明后验概率分布会在$\\mu_{ML}$处形成一个尖峰；   \n",
    "（3）当$N$固定，若$\\sigma_0^2\\rightarrow\\infty$时，后验均值就变成了$\\mu_{ML}$，这个容易理解，$\\sigma_0^2\\rightarrow\\infty$时，先验分布很平，几乎不能提供有用的先验信息；   \n",
    "\n",
    "下图演示了后验概率分布随着样本量$N$增加时的变化，其中$N=0$表示先验概率分布：  \n",
    "\n",
    "<img src=\"../images/高斯分布_均值的贝叶斯推断.png\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be07d05",
   "metadata": {},
   "source": [
    "#### $\\mu$已知的情况\n",
    "当$\\mu$已知时，我们的似然函数可以写作：   \n",
    "\n",
    "$$\n",
    "p(X\\mid\\lambda)=\\prod_{n=1}^NN(x_n\\mid\\mu,\\lambda^{-1})\\propto\\lambda^{\\frac{N}{2}}exp[-\\frac{\\lambda}{2}\\sum_{n=1}^N(x_n-\\mu)^2]\n",
    "$$  \n",
    "\n",
    "其中，$\\lambda=\\frac{1}{\\sigma^2}$，这里用精度表示，后续的推导会更方便，从上面的形式可以看出，对应的共轭先验分布应该满足：（1）正比于$\\lambda$的幂指数；（2）同时正比于$\\lambda$的线性函数的指数；这样的分布有的，那就是Gamma分布：   \n",
    "\n",
    "$$\n",
    "Gam(\\lambda\\mid a,b)=\\frac{1}{\\Gamma(a)}b^a\\lambda^{a-1}exp(-b\\lambda)\n",
    "$$\n",
    "\n",
    "不同$a,b$取值下的Gamma分布如下图：   \n",
    "\n",
    "<img src=\"../images/gamma分布.png\" width=\"40%\">\n",
    "\n",
    "直接说一下Gamma分布的均值为$E[\\lambda]=\\frac{a}{b}$，方差为$var[\\lambda]=\\frac{a}{b^2}$，接下来考虑一个后验分布的形式，假设我们已经定义了一个先验分布$Gam(\\lambda\\mid a_0,b_0)$，然后乘以上面的似然函数：   \n",
    "\n",
    "$$\n",
    "p(\\lambda\\mid X)\\propto \\lambda^{a_0-1}\\lambda^{\\frac{N}{2}}exp[-b_0\\lambda-\\frac{\\lambda}{2}\\sum_{n=1}^N(x_n-\\mu)^2]\n",
    "$$  \n",
    "\n",
    "这显然也是一个Gamma分布的形式，不妨记为$Gam(\\lambda\\mid a_N,b_N)$，其中：   \n",
    "$$\n",
    "a_N=a_0+\\frac{N}{2}\\\\\n",
    "b_N=b_0+\\frac{1}{2}\\sum_{n=1}^N(x_n-\\mu)^2=b_0+\\frac{N}{2}\\sigma_{ML}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d92fcb",
   "metadata": {},
   "source": [
    "#### $\\mu$和$\\sigma^2$均未知的情况\n",
    "\n",
    "大家可能已经能猜想到，这种情况下的共轭先验应该既与高斯分布相关，又与Gamma分布有关，下面推导一下：   \n",
    "\n",
    "$$\n",
    "p(X\\mid\\mu,\\lambda)=\\prod_{n=1}^N(\\frac{\\lambda}{2\\pi})^{\\frac{1}{2}}exp[-\\frac{\\lambda}{2}(x_n-\\mu)^2]\\\\\n",
    "\\propto exp(-\\frac{N\\lambda\\mu^2}{2}+\\lambda\\mu\\sum_{n=1}^Nx_n)[\\lambda^{\\frac{N}{2}}exp(-\\frac{\\lambda}{2}\\sum_{n=1}^Nx_n^2)]\n",
    "$$  \n",
    "\n",
    "可以发现，右侧$\\lambda^{\\frac{N}{2}}exp(-\\frac{\\lambda}{2}\\sum_{n=1}^Nx_n^2)$是关于$\\lambda$的Gamma分布的形式，左侧$exp(-\\frac{N\\lambda\\mu^2}{2}+\\lambda\\mu\\sum_{n=1}^Nx_n)$可以看做$\\lambda$已知的关于$\\mu$的高斯分布的形式，所以，我们的先验分布可以写作如下形式：   \n",
    "\n",
    "$$\n",
    "p(\\mu,\\lambda)=p(\\mu\\mid\\lambda)p(\\lambda)\n",
    "$$  \n",
    "\n",
    "其中$p(\\mu\\mid\\lambda)$是一个高斯分布，$p(\\lambda)$是一个Gamma分布，经过归一化整理，我们的先验分布可以写作如下形式：   \n",
    "\n",
    "$$\n",
    "p(\\mu,\\lambda)=N(\\mu\\mid\\mu_0,(\\beta\\lambda)^{-1})Gam(\\lambda\\mid a,b)\n",
    "$$  \n",
    "\n",
    "这里，$\\beta$是一个超参数，类比上面的样本量$N$，该分布也被称为**高斯-Gamma分布**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775722b",
   "metadata": {},
   "source": [
    "## 指数族分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f72391",
   "metadata": {},
   "source": [
    "### 指数族分布的形式\n",
    "前面几节介绍的概率分布其实可以用一种统一的形式的来表示：    \n",
    "\n",
    "$$\n",
    "p(x\\mid\\eta)=h(x)g(\\eta)exp[\\eta^T\\mu(x)]\n",
    "$$   \n",
    "\n",
    "这便是指数家族分布，其中$g(\\eta)$可以看做归一化系数，下面来看看前面介绍过的几种分布变换为指数族分布后的形式\n",
    "\n",
    "#### 伯努利分布\n",
    "\n",
    "$$\n",
    "p(x\\mid\\mu)=\\mu^x(1-\\mu)^{1-x}\\\\\n",
    "=exp[xlog\\mu+(1-x)log(1-mu)]\\\\\n",
    "=(1-\\mu)exp[log(\\frac{\\mu}{1-\\mu})x]\n",
    "$$  \n",
    "\n",
    "所以，$\\eta=ln(\\frac{\\mu}{1-\\mu})$，可以推得：   \n",
    "$$\n",
    "\\mu=\\sigma(\\eta)=\\frac{1}{1+exp(-\\eta)}\n",
    "$$  \n",
    "\n",
    "所以对应的指数家族的函数关系为：   \n",
    "\n",
    "$$\n",
    "h(x)=1,g(\\eta)=1-\\mu=1-\\sigma(\\eta)=\\sigma(-\\eta),\\mu(x)=x\n",
    "$$   \n",
    "\n",
    "#### 单一观测的多项式分布\n",
    "\n",
    "$$\n",
    "p(x\\mid\\mu)=\\prod_{k=1}^M\\mu_k^{x_k}=exp[\\sum_{k=1}^Mx_klog\\mu_k]\n",
    "$$   \n",
    "\n",
    "所以：   \n",
    "\n",
    "$$\n",
    "h(x)=1\\\\\n",
    "g(\\eta)=1\\\\\n",
    "\\mu(x)=(x_1,...,x_M)^T=x\\\\\n",
    "\\eta=(log\\mu_1,...,log\\mu_M)^T\n",
    "$$  \n",
    "\n",
    "注意：$\\eta_k$之间不是相互独立的，因为有一个约束$\\sum_{k=1}^M\\mu_k=1$   \n",
    "\n",
    "\n",
    "#### 一元高斯分布\n",
    "$$\n",
    "p(x\\mid\\mu,\\sigma^2)=\\frac{1}{(2\\pi\\sigma^2)^{\\frac{1}{2}}}exp[-\\frac{1}{2\\sigma^2}(x-\\mu)^2]\\\\\n",
    "=\\frac{1}{(2\\pi\\sigma^2)^{\\frac{1}{2}}}exp[-\\frac{1}{2\\sigma^2}x^2+\\frac{\\mu}{\\sigma^2}x-\\frac{1}{2\\sigma^2}\\mu^2]\\\\\n",
    "=\\frac{1}{(2\\pi\\sigma^2)^{\\frac{1}{2}}}exp[-\\frac{1}{2\\sigma^2}\\mu^2]exp[-\\frac{1}{2\\sigma^2}x^2+\\frac{\\mu}{\\sigma^2}x]\n",
    "$$  \n",
    "\n",
    "我们可以令：   \n",
    "\n",
    "$$\n",
    "\\eta=(\\frac{\\mu}{\\sigma^2},\\frac{-1}{2\\sigma^2})^T\\\\\n",
    "\\mu(x)=(x,x^2)^T\\\\\n",
    "$$   \n",
    "最后可以推得：   \n",
    "\n",
    "$$\n",
    "h(x)=(2\\pi)^{2\\frac{1}{2}}\\\\\n",
    "g(\\eta)=(-2\\eta_2)^{\\frac{1}{2}}exp(\\frac{\\eta_1^2}{4\\eta_2})\n",
    "$$   \n",
    "\n",
    "剩下地，如多元高斯分布，Gamma分布，beta分布，狄利克雷分布，多项式分布，二项分布等都可以通过类似的方式转换为指数家族分布，那么问题就来了，将这些分布转换为指数族分布的形式有啥好处呢？自然是为了计算上更加方便，特别是求极大似然估计以及求共轭先验上，下面分别介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be968f96",
   "metadata": {},
   "source": [
    "### 极大似然估计\n",
    "在做极大似然估计前我们先看一个一般的结论，由于指数族分布必然是一个概率分布，所以有：   \n",
    "\n",
    "$$\n",
    "g(\\eta)\\int h(x)exp[\\eta^T\\mu(x)]dx=1\n",
    "$$   \n",
    "\n",
    "两边对$\\eta$求梯度，有：   \n",
    "\n",
    "$$\n",
    "\\nabla g(\\eta)\\int h(x)exp[\\eta^T\\mu(x)]dx+g(\\eta)\\int h(x)exp[\\eta^T\\mu(x)]u(x)dx=0\\\\\n",
    "\\Leftrightarrow -\\nabla g(\\eta)\\frac{1}{g(\\eta)}=g(\\eta)\\int h(x)exp[\\eta^T\\mu(x)]u(x)dx=E[\\mu(x)]\\\\\n",
    "\\Leftrightarrow -\\nabla ln[g(\\eta)]=E[\\mu(x)]\n",
    "$$   \n",
    "\n",
    "注意，上面的等式是恒成立的哦，我们自然就会猜想，如果是求极大似然估计，它的形式应该也会和上面的等式差不多才对，下面省略求解过程，直接写出极大似然估计的结果：    \n",
    "\n",
    "$$\n",
    "-\\nabla ln[g(\\eta_{ML})]=\\frac{1}{N}\\sum_{n=1}^N\\mu(x_n)\n",
    "$$  \n",
    "\n",
    "显然，当$N\\rightarrow\\infty$时，有$\\frac{1}{N}\\sum_{n=1}^N\\mu(x_n)=E[\\mu(x)]$，以及$\\eta_{ML}=\\eta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9d9fa",
   "metadata": {},
   "source": [
    "### 共轭先验\n",
    "\n",
    "对于指数分布家族的任何成员，都存在一个共轭先验，可以写作如下的形式：   \n",
    "\n",
    "$$\n",
    "p(\\eta\\mid \\chi,\\nu)=f(\\chi,\\nu)g(\\eta)^\\nu exp[\\nu\\eta^T\\chi]\n",
    "$$  \n",
    "\n",
    "其中，$f(\\chi,\\nu)$是归一化系数，为了验证该分布是共轭先验，让它与如下的似然函数相乘：    \n",
    "\n",
    "$$\n",
    "p(X\\mid\\eta)=(\\prod_{n=1}^Nh(x_n))g(\\eta)^Nexp[\\eta^T\\sum_{n=1}^N\\mu(x_n)]\n",
    "$$  \n",
    "\n",
    "可推得：   \n",
    "\n",
    "$$\n",
    "p(\\eta\\mid x,\\chi,\\nu)\\propto g(\\eta)^{\\nu+N}exp[\\eta^T(\\sum_{n=1}^N\\mu(x_n)+\\nu\\chi)]\n",
    "$$  \n",
    "\n",
    "这与先验分布具有相同的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b7006",
   "metadata": {},
   "source": [
    "### 小结一下\n",
    "\n",
    "用下图对概率分布这几节的内容做个简单梳理：   \n",
    "![avatar](../images/概率分布之间的关系.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b52364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcbc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACG",
   "language": "python",
   "name": "acg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
